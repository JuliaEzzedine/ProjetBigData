# Real-Time Weather Monitoring System using Apache Kafka

## 1. Project Description

This project demonstrates a real-time data streaming pipeline using **Apache Kafka**.  
The objective is to simulate meteorological sensors that continuously generate weather data and stream this data in real time.

The application is fully containerized using **Docker**, which makes the setup simple and reproducible.

---

## 2. Chosen Tool

### Apache Kafka

Apache Kafka was chosen because it is a distributed streaming platform designed for handling real-time data.  
It is widely used in Big Data architectures to ingest, buffer, and distribute large volumes of data with low latency.

Kafka is well suited for this use case because weather data is:
- continuous  
- produced in real time  
- potentially generated by many sensors  

---

## 3. Architecture Overview

The system is composed of **four Docker containers**:

- **Zookeeper**: manages Kafka coordination  
- **Kafka Broker**: handles message storage and streaming  
- **Weather Producer (Python)**: simulates weather sensors and sends data to Kafka  
- **Weather Consumer (Python)**: consumes and displays weather data in real time  

### Data Flow


---
## 4. Data Format

Each message sent to Kafka is a JSON object containing weather measurements:

```json
{
  "station_id": "PARIS_01",
  "timestamp": "2025-12-17T18:05:00",
  "temperature": 21.4,
  "humidity": 63,
  "pressure": 1012,
  "wind_speed": 5.3
}
``` 

## 5. Installation and Execution of the Project

The project is executed using Docker Compose.

### Execution Steps
1. The project is launched from a terminal using the following command:
```bash
docker-compose up
```
Docker Desktop automatically starts all containers defined in the `docker-compose.yml` file.

Once the execution is launched, the following four containers are visible in the Docker Desktop interface:

- **Zookeeper**: Kafka cluster coordination service  
- **Kafka**: broker responsible for message storage and message streaming  
- **Weather Producer**: generation and transmission of weather data  
- **Weather Consumer**: real-time consumption and display of weather data  

The containers can be started, stopped, or restarted directly from Docker Desktop using the **Play** and **Pause** buttons.

The logs of each container are accessible from Docker Desktop and allow verification of:
- data being sent by the producer,
- data being received by the consumer,
- correct operation of Kafka and Zookeeper.

