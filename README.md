# Real-Time Weather Monitoring System using Apache Kafka

## 1. Project Description

This project demonstrates a real-time data streaming pipeline using **Apache Kafka**.  
The objective is to simulate meteorological sensors that continuously generate weather data and stream this data in real time.

The application is fully containerized using **Docker**, which makes the setup simple and reproducible.

---

## 2. Chosen Tool

### Apache Kafka

Apache Kafka was chosen because it is a distributed streaming platform designed for handling real-time data.  
It is widely used in Big Data architectures to ingest, buffer, and distribute large volumes of data with low latency.

Kafka is well suited for this use case because weather data is:
- continuous  
- produced in real time  
- potentially generated by many sensors  

---

## 3. Architecture Overview

The system is composed of **four Docker containers**:

- **Zookeeper**: manages Kafka coordination  
- **Kafka Broker**: handles message storage and streaming  
- **Weather Producer (Python)**: simulates weather sensors and sends data to Kafka  
- **Weather Consumer (Python)**: consumes and displays weather data in real time  

### Data Flow


---
## 4. Data Format

Each message sent to Kafka is a JSON object containing weather measurements:

```json
{
  "station_id": "PARIS_01",
  "timestamp": "2025-12-17T18:05:00",
  "temperature": 21.4,
  "humidity": 63,
  "pressure": 1012,
  "wind_speed": 5.3
}
``` 

## 5. Installation and Execution of the Project

The project is executed using Docker Compose.

### Execution Steps
1. The project is launched from a terminal using the following command:
```bash
docker-compose up
```
Docker Desktop automatically starts all containers defined in the `docker-compose.yml` file.

Once the execution is launched, the following four containers are visible in the Docker Desktop interface:

- **Zookeeper**: Kafka cluster coordination service  
- **Kafka**: broker responsible for message storage and message streaming  
- **Weather Producer**: generation and transmission of weather data  
- **Weather Consumer**: real-time consumption and display of weather data  

The containers can be started, stopped, or restarted directly from Docker Desktop using the **Play** and **Pause** buttons.

The logs of each container are accessible from Docker Desktop and allow verification of:
- data being sent by the producer,
- data being received by the consumer,
- correct operation of Kafka and Zookeeper.


## 6. Execution Proof and Screenshots

This section presents screenshots taken from **Docker Desktop** to demonstrate the correct execution of the project and the interaction between all components of the Kafka pipeline.

---

### Kafka Broker

![Kafka](screenshots/kafka.jpg)

This screenshot shows the **Kafka broker container** running successfully.  
The logs indicate that Kafka is correctly started, that the consumer group is registered, and that the broker is handling message coordination and leader elections properly.  
This confirms that Kafka is operational and ready to stream data.

---

### Zookeeper

![Zookeeper](screenshots/zookeeper.jpg)

This screenshot shows the **Zookeeper container** running without errors.  
Zookeeper is responsible for coordinating the Kafka cluster.  
The logs confirm that Zookeeper started successfully, initialized its data directories, and is listening for Kafka connections.

---

### Weather Producer

![Producer](screenshots/producer.jpg)

This screenshot shows the **Weather Producer container**.  
The logs display multiple messages being sent to Kafka, each containing simulated weather data (station ID, timestamp, temperature, humidity, pressure, and wind speed).  
This confirms that the producer is correctly generating and publishing data to the Kafka topic in real time.

---

### Weather Consumer

![Consumer](screenshots/consumer.jpg)

This screenshot shows the **Weather Consumer container**.  
The logs display weather messages received from Kafka, corresponding to the data sent by the producer.  
This confirms that the consumer is successfully subscribing to the Kafka topic and consuming messages in real time.

---

A REVOIR ### Summary

These screenshots demonstrate that:
- **All Docker containers are running correctly**,  
- **Kafka and Zookeeper are properly configured**,  
- **The producer successfully sends data to Kafka**,  
- **The consumer successfully receives and displays the streamed data**.

This validates the correct end-to-end execution of the **real-time weather monitoring system**.

